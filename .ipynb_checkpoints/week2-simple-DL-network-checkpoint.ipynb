{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "colab_type": "code",
    "id": "Akj_yq0zTUza",
    "outputId": "fd933e90-ebff-4427-d647-885f1dd53c40"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uGEdTUVlWx-F"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yXt3CwyLU1zO"
   },
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "  Dense(32, input_shape=(784,)),\n",
    "  Activation('relu'),\n",
    "  Dense(10),\n",
    "  Activation('softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLiJo3SuWMCj"
   },
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(500, input_dim=784))\n",
    "model2.add(Activation('relu')) \n",
    "model2.add(Dense(300))\n",
    "model2.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XdJaos9WW9Ft"
   },
   "source": [
    "# COMPILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "AUDi5oBFWo8W",
    "outputId": "c1651366-8d77-417a-825e-bea3ad0ac757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "4CEeSdnLdzzt",
    "outputId": "b0235885-5c83-4f1a-b23a-4fdb7628dcc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "def load_data():\n",
    "    print ('Loading data...')\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "    X_train = np.reshape(X_train, (60000, 784))\n",
    "    X_test = np.reshape(X_test, (10000, 784))\n",
    "\n",
    "    print ('Data loaded.')\n",
    "    return [X_train, X_test, y_train, y_test]\n",
    "X_train, X_test, y_train, y_test = load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 758
    },
    "colab_type": "code",
    "id": "Mw7ecByKe7DQ",
    "outputId": "7fed4948-595a-442b-a1e0-3c36db00bb3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      " - 15s - loss: 0.3457 - acc: 0.9037 - val_loss: 0.2207 - val_acc: 0.9344\n",
      "Epoch 2/10\n",
      " - 5s - loss: 0.2014 - acc: 0.9416 - val_loss: 0.1784 - val_acc: 0.9455\n",
      "Epoch 3/10\n",
      " - 5s - loss: 0.1655 - acc: 0.9527 - val_loss: 0.1479 - val_acc: 0.9581\n",
      "Epoch 4/10\n",
      " - 5s - loss: 0.1435 - acc: 0.9594 - val_loss: 0.1445 - val_acc: 0.9573\n",
      "Epoch 5/10\n",
      " - 5s - loss: 0.1293 - acc: 0.9638 - val_loss: 0.1449 - val_acc: 0.9586\n",
      "Epoch 6/10\n",
      " - 5s - loss: 0.1189 - acc: 0.9663 - val_loss: 0.1307 - val_acc: 0.9651\n",
      "Epoch 7/10\n",
      " - 6s - loss: 0.1113 - acc: 0.9680 - val_loss: 0.1371 - val_acc: 0.9635\n",
      "Epoch 8/10\n",
      " - 5s - loss: 0.1034 - acc: 0.9708 - val_loss: 0.1380 - val_acc: 0.9634\n",
      "Epoch 9/10\n",
      " - 6s - loss: 0.0993 - acc: 0.9723 - val_loss: 0.1331 - val_acc: 0.9645\n",
      "Epoch 10/10\n",
      " - 6s - loss: 0.0935 - acc: 0.9731 - val_loss: 0.1295 - val_acc: 0.9654\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb5a51efb38>"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras.callbacks as cb\n",
    "class LossHistory(cb.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        batch_loss = logs.get('loss')\n",
    "        self.losses.append(batch_loss)\n",
    "\n",
    "\n",
    "epochs=10\n",
    "batch=32\n",
    "history = LossHistory()\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch,\n",
    "                    callbacks=[history],\n",
    "                    validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "3BB-yO_2cexg",
    "outputId": "501d3209-128a-4fbe-e459-9e100ddc7ab5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3fc4ef4b8fef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m model.fit(X_train, y_train, epoch=epochs, batch_size=batch,\n\u001b[1;32m      3\u001b[0m                  \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# 畫圖\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                  validation_data=(X_test, y_test), verbose=2)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_data' is not defined"
     ]
    }
   ],
   "source": [
    " \n",
    "\n",
    "model.fit(X_train, y_train, epoch=epochs, batch_size=batch,\n",
    "                  callbacks=[history], # 畫圖\n",
    "                  validation_data=(X_test, y_test), verbose=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JyHBd671hHMe"
   },
   "source": [
    "老師的code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "F3pUexqhWJeS",
    "outputId": "ca097248-b217-413d-ca3b-0cc7f76afde0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Data loaded.\n",
      "Compiling Model ... \n",
      "Model compield in 0.044791221618652344 seconds\n",
      "Training model...\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      " - 1s - loss: 0.3082 - acc: 0.9134 - val_loss: 0.1584 - val_acc: 0.9530\n",
      "Epoch 2/50\n",
      " - 1s - loss: 0.1298 - acc: 0.9623 - val_loss: 0.1043 - val_acc: 0.9671\n",
      "Epoch 3/50\n",
      " - 1s - loss: 0.0857 - acc: 0.9756 - val_loss: 0.0858 - val_acc: 0.9743\n",
      "Epoch 4/50\n",
      " - 1s - loss: 0.0626 - acc: 0.9814 - val_loss: 0.0781 - val_acc: 0.9763\n",
      "Epoch 5/50\n",
      " - 1s - loss: 0.0483 - acc: 0.9854 - val_loss: 0.0638 - val_acc: 0.9795\n",
      "Epoch 6/50\n",
      " - 1s - loss: 0.0367 - acc: 0.9895 - val_loss: 0.0667 - val_acc: 0.9798\n",
      "Epoch 7/50\n",
      " - 1s - loss: 0.0293 - acc: 0.9914 - val_loss: 0.0718 - val_acc: 0.9768\n",
      "Epoch 8/50\n",
      " - 1s - loss: 0.0229 - acc: 0.9933 - val_loss: 0.0641 - val_acc: 0.9805\n",
      "Epoch 9/50\n",
      " - 1s - loss: 0.0172 - acc: 0.9955 - val_loss: 0.0648 - val_acc: 0.9817\n",
      "Epoch 10/50\n",
      " - 1s - loss: 0.0140 - acc: 0.9965 - val_loss: 0.0852 - val_acc: 0.9752\n",
      "Epoch 11/50\n",
      " - 1s - loss: 0.0106 - acc: 0.9973 - val_loss: 0.0623 - val_acc: 0.9825\n",
      "Epoch 12/50\n",
      " - 1s - loss: 0.0090 - acc: 0.9977 - val_loss: 0.0644 - val_acc: 0.9828\n",
      "Epoch 13/50\n",
      " - 1s - loss: 0.0066 - acc: 0.9985 - val_loss: 0.0682 - val_acc: 0.9820\n",
      "Epoch 14/50\n",
      " - 1s - loss: 0.0057 - acc: 0.9985 - val_loss: 0.0670 - val_acc: 0.9827\n",
      "Epoch 15/50\n",
      " - 1s - loss: 0.0043 - acc: 0.9990 - val_loss: 0.0689 - val_acc: 0.9836\n",
      "Epoch 16/50\n",
      " - 1s - loss: 0.0033 - acc: 0.9993 - val_loss: 0.0667 - val_acc: 0.9839\n",
      "Epoch 17/50\n",
      " - 1s - loss: 0.0026 - acc: 0.9996 - val_loss: 0.0748 - val_acc: 0.9809\n",
      "Epoch 18/50\n",
      " - 1s - loss: 0.0022 - acc: 0.9996 - val_loss: 0.0705 - val_acc: 0.9823\n",
      "Epoch 19/50\n",
      " - 1s - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0745 - val_acc: 0.9824\n",
      "Epoch 20/50\n",
      " - 1s - loss: 0.0016 - acc: 0.9996 - val_loss: 0.0726 - val_acc: 0.9834\n",
      "Epoch 21/50\n",
      " - 1s - loss: 0.0013 - acc: 0.9998 - val_loss: 0.0773 - val_acc: 0.9826\n",
      "Epoch 22/50\n",
      " - 1s - loss: 0.0011 - acc: 0.9999 - val_loss: 0.0786 - val_acc: 0.9827\n",
      "Epoch 23/50\n",
      " - 1s - loss: 0.0011 - acc: 0.9998 - val_loss: 0.0913 - val_acc: 0.9808\n",
      "Epoch 24/50\n",
      " - 1s - loss: 9.1100e-04 - acc: 0.9999 - val_loss: 0.0810 - val_acc: 0.9831\n",
      "Epoch 25/50\n",
      " - 1s - loss: 7.0767e-04 - acc: 0.9999 - val_loss: 0.0822 - val_acc: 0.9827\n",
      "Epoch 26/50\n",
      " - 1s - loss: 6.5006e-04 - acc: 0.9999 - val_loss: 0.0873 - val_acc: 0.9828\n",
      "Epoch 27/50\n",
      " - 1s - loss: 5.6581e-04 - acc: 0.9999 - val_loss: 0.0956 - val_acc: 0.9808\n",
      "Epoch 28/50\n",
      " - 1s - loss: 5.1220e-04 - acc: 1.0000 - val_loss: 0.0888 - val_acc: 0.9836\n",
      "Epoch 29/50\n",
      " - 1s - loss: 4.9680e-04 - acc: 1.0000 - val_loss: 0.0919 - val_acc: 0.9828\n",
      "Epoch 30/50\n",
      " - 1s - loss: 3.9340e-04 - acc: 1.0000 - val_loss: 0.0982 - val_acc: 0.9835\n",
      "Epoch 31/50\n",
      " - 1s - loss: 4.7857e-04 - acc: 0.9999 - val_loss: 0.0886 - val_acc: 0.9840\n",
      "Epoch 32/50\n",
      " - 1s - loss: 3.6920e-04 - acc: 1.0000 - val_loss: 0.0965 - val_acc: 0.9839\n",
      "Epoch 33/50\n",
      " - 1s - loss: 4.0886e-04 - acc: 0.9999 - val_loss: 0.0927 - val_acc: 0.9842\n",
      "Epoch 34/50\n",
      " - 1s - loss: 3.2498e-04 - acc: 1.0000 - val_loss: 0.0943 - val_acc: 0.9846\n",
      "Epoch 35/50\n",
      " - 1s - loss: 3.3235e-04 - acc: 1.0000 - val_loss: 0.1077 - val_acc: 0.9823\n",
      "Epoch 36/50\n",
      " - 1s - loss: 3.3732e-04 - acc: 0.9999 - val_loss: 0.0998 - val_acc: 0.9835\n",
      "Epoch 37/50\n",
      " - 1s - loss: 3.6723e-04 - acc: 1.0000 - val_loss: 0.1008 - val_acc: 0.9838\n",
      "Epoch 38/50\n",
      " - 1s - loss: 3.0721e-04 - acc: 1.0000 - val_loss: 0.1103 - val_acc: 0.9838\n",
      "Epoch 39/50\n",
      " - 1s - loss: 3.5316e-04 - acc: 1.0000 - val_loss: 0.1032 - val_acc: 0.9843\n",
      "Epoch 40/50\n",
      " - 1s - loss: 3.7063e-04 - acc: 1.0000 - val_loss: 0.1046 - val_acc: 0.9839\n",
      "Epoch 41/50\n",
      " - 1s - loss: 3.0013e-04 - acc: 1.0000 - val_loss: 0.1081 - val_acc: 0.9836\n",
      "Epoch 42/50\n",
      " - 1s - loss: 3.0407e-04 - acc: 1.0000 - val_loss: 0.1076 - val_acc: 0.9841\n",
      "Epoch 43/50\n",
      " - 1s - loss: 3.2728e-04 - acc: 1.0000 - val_loss: 0.1091 - val_acc: 0.9833\n",
      "Epoch 44/50\n",
      " - 1s - loss: 2.9000e-04 - acc: 1.0000 - val_loss: 0.1146 - val_acc: 0.9837\n",
      "Epoch 45/50\n",
      " - 1s - loss: 2.7659e-04 - acc: 1.0000 - val_loss: 0.1129 - val_acc: 0.9830\n",
      "Epoch 46/50\n",
      " - 1s - loss: 2.7457e-04 - acc: 1.0000 - val_loss: 0.1144 - val_acc: 0.9827\n",
      "Epoch 47/50\n",
      " - 1s - loss: 2.6998e-04 - acc: 1.0000 - val_loss: 0.1157 - val_acc: 0.9838\n",
      "Epoch 48/50\n",
      " - 1s - loss: 2.6947e-04 - acc: 1.0000 - val_loss: 0.1204 - val_acc: 0.9838\n",
      "Epoch 49/50\n",
      " - 1s - loss: 2.6903e-04 - acc: 1.0000 - val_loss: 0.1139 - val_acc: 0.9847\n",
      "Epoch 50/50\n",
      " - 1s - loss: 2.6891e-04 - acc: 1.0000 - val_loss: 0.1135 - val_acc: 0.9842\n",
      "Training duration : 44.89660596847534\n",
      "10000/10000 [==============================] - 1s 68us/step\n",
      "Network's test score [loss, accuracy]: [0.11354363278061216, 0.9842]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEICAYAAAC+iFRkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRPoAhb2ISB+gsBcR6QMU9iIifcD/B5/KWfSOR0M1AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "import keras.callbacks as cb\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "\n",
    "\n",
    "class LossHistory(cb.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        batch_loss = logs.get('loss')\n",
    "        self.losses.append(batch_loss)\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    print ('Loading data...')\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "    X_train = np.reshape(X_train, (60000, 784))\n",
    "    X_test = np.reshape(X_test, (10000, 784))\n",
    "\n",
    "    print ('Data loaded.')\n",
    "    return [X_train, X_test, y_train, y_test]\n",
    "\n",
    "\n",
    "def init_model():\n",
    "    start_time = time.time()\n",
    "    print ('Compiling Model ... ')\n",
    "    model = Sequential()\n",
    "    model.add(Dense(500, input_dim=784)) \n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    rms = RMSprop()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rms, metrics=['accuracy'])\n",
    "    print ('Model compield in {0} seconds'.format(time.time() - start_time))\n",
    "    return model\n",
    "\n",
    "\n",
    "def run_network(data=None, model=None, epochs=20, batch=256):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        if data is None:\n",
    "            X_train, X_test, y_train, y_test = load_data()\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = data\n",
    "\n",
    "        if model is None:\n",
    "            model = init_model()\n",
    "\n",
    "        history = LossHistory()\n",
    "\n",
    "        print ('Training model...')\n",
    "        model.fit(X_train, y_train, epochs=epochs, batch_size=batch,\n",
    "                    callbacks=[history],\n",
    "                    validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "        print (\"Training duration : {0}\".format(time.time() - start_time))\n",
    "        score = model.evaluate(X_test, y_test, batch_size=16)\n",
    "\n",
    "        print (\"Network's test score [loss, accuracy]: {0}\".format(score))\n",
    "        return model, history.losses\n",
    "    except KeyboardInterrupt:\n",
    "        print (' KeyboardInterrupt')\n",
    "        return model, history.losses\n",
    "\n",
    "\n",
    "def plot_losses(losses):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(losses)\n",
    "    ax.set_title('Loss per batch')\n",
    "    fig.show()\n",
    "\n",
    "model, losses = run_network(epochs=50, batch=256)\n",
    "plot_losses(losses)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "week2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
