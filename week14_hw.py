# -*- coding: utf-8 -*-
"""week14_hw.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QwxCOJpPItzXjF6cPirDnOKpX8NjdH17

# read file
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow
print(tensorflow.__version__)
from google.colab import drive
drive.mount('/content/drive')

import os
os.chdir('drive/My Drive/dataset/face')

!ls

"""# prepare"""

!pip install git+https://github.com/rcmalli/keras-vggface.git

!sudo pip install mtcnn

"""# Face Recognition"""

# example of face detection with mtcnn
from numpy import expand_dims
from matplotlib import pyplot
from PIL import Image
from numpy import asarray
from mtcnn.mtcnn import MTCNN
from keras_vggface.vggface import VGGFace
from keras_vggface.utils import preprocess_input
from keras_vggface.utils import decode_predictions
import matplotlib.pyplot as plt

# extract a single face from a given photograph
def extract_face(filename, required_size=(224, 224)):
	# load image from file
	pixels = pyplot.imread(filename)
	# create the detector, using default weights
	detector = MTCNN()
	# detect faces in the image
	results = detector.detect_faces(pixels)
	# extract the bounding box from the first face
	x1, y1, width, height = results[0]['box']
	x2, y2 = x1 + width, y1 + height
	# extract the face
	face = pixels[y1:y2, x1:x2]
	# resize pixels to the model size
	image = Image.fromarray(face)
	image = image.resize(required_size)
	face_array = asarray(image)
	return face_array

import glob
data = []
folder_list = glob.glob('*')
folder_list = [f for f in folder_list if f != 'test']

print()
db =[]
for folder in folder_list:
  i=1
  filenames = glob.glob(folder+'/*.jpg')
  
  print('class:',folder)
  plt.figure(figsize=(16,16))
  for f in filenames:
    pixels = extract_face(f)
    db.append(f)
    plt.subplot(1,10,i)
    plt.imshow(pixels)
    i+=1
  plt.show()
print(len(db))

"""# Face Identification"""

# face verification with the VGGFace2 model
from matplotlib import pyplot
from PIL import Image
from numpy import asarray
from scipy.spatial.distance import cosine
from mtcnn.mtcnn import MTCNN
from keras_vggface.vggface import VGGFace
from keras_vggface.utils import preprocess_input

# extract a single face from a given photograph
def extract_face(filename, required_size=(224, 224)):
	# load image from file
	pixels = pyplot.imread(filename)
	# create the detector, using default weights
	detector = MTCNN()
	# detect faces in the image
	results = detector.detect_faces(pixels)
	# extract the bounding box from the first face
	x1, y1, width, height = results[0]['box']
	x2, y2 = x1 + width, y1 + height
	# extract the face
	face = pixels[y1:y2, x1:x2]
	# resize pixels to the model size
	image = Image.fromarray(face)
	image = image.resize(required_size)
	face_array = asarray(image)
	return face_array

# extract faces and calculate face embeddings for a list of photo files
def get_embeddings(filenames):
	# extract faces
	faces = [extract_face(f) for f in filenames]
	# convert into an array of samples
	samples = asarray(faces, 'float32')
	# prepare the face for the model, e.g. center pixels
	samples = preprocess_input(samples, version=2)
	# create a vggface model
	model = VGGFace(model='resnet50', include_top=False, input_shape=(224, 224, 3), pooling='avg')
	# perform prediction
	yhat = model.predict(samples)
	return yhat

# determine if a candidate face is a match for a known face
def is_match(known_embedding, candidate_embedding, thresh=0.5):
	# calculate distance between embeddings
	score = cosine(known_embedding, candidate_embedding) #把向量夾角當score
	#if score <= thresh:
	#	print('>face is a Match (%.3f <= %.3f)' % (score, thresh))
	#else:
	#	print('>face is NOT a Match (%.3f > %.3f)' % (score, thresh))
	return 1-score

"""## 拿到embedding"""

embeddings = get_embeddings(db)
num_of_class = int(embeddings.shape[0]/10)
print(embeddings.shape,num_of_class)

print(embeddings)
print('shape :',embeddings.shape)

# 製作avg vector
avgV_list = []
for i in range(num_of_class):
  from_select = i*10
  to_select = (i+1)*10
  avg_vector = embeddings[from_select:to_select].mean(axis=0)
  avgV_list.append(avg_vector)

filenames = glob.glob('test/*.jpg')
plt.figure(figsize=(16,8))
i=1
for f in filenames:
  pixels = extract_face(f)
  db.append(f)
  plt.subplot(1,len(filenames),i)
  plt.imshow(pixels)
  i+=1
plt.show()

test_filenames = glob.glob('test/*.jpg')
test_embeddings = get_embeddings(test_filenames)
for i in range(len(test_filenames)):
  print('========',test_filenames[i],'========')
  scores = []
  for c in range(len(folder_list)):
    score = is_match(avgV_list[c], test_embeddings[i])
    #print(score,folder_list[c])
    scores.append(score)
  max_value = max(scores)
  if max_value>0.4:
    maximum_index = scores.index(max_value)
    print(folder_list[maximum_index])
  else:
    print('not in the dataset')